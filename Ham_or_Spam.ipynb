{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6XNphocpd_l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Neuraaal/Assign_5/mail_data.csv\"\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "g3K-MLfDp7ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "label_encoder = LabelEncoder()\n",
        "data['Category'] = label_encoder.fit_transform(data['Category'])"
      ],
      "metadata": {
        "id": "ZERzrkQTqAT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Message']\n",
        "y = data['Category']"
      ],
      "metadata": {
        "id": "LDW3yR2bqPZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "KM4jYXjjqUZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "Dvbizb04qWN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded = pad_sequences(X_train_seq, maxlen=100)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=100)"
      ],
      "metadata": {
        "id": "EYALkmcvqYEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iVgR-Ffqa2L",
        "outputId": "e1006d05-0a30-49a4-c8a9-a77ccd726fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nDl8IJ1OqckD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKmUa2RGqeTb",
        "outputId": "8a2008e8-277c-4135-fdea-1959d2dcd474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 150ms/step - accuracy: 0.8919 - loss: 0.3219 - val_accuracy: 0.9675 - val_loss: 0.1160\n",
            "Epoch 2/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - accuracy: 0.9883 - loss: 0.0449 - val_accuracy: 0.9809 - val_loss: 0.0772\n",
            "Epoch 3/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - accuracy: 0.9949 - loss: 0.0244 - val_accuracy: 0.9787 - val_loss: 0.0903\n",
            "Epoch 4/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - accuracy: 0.9982 - loss: 0.0134 - val_accuracy: 0.9798 - val_loss: 0.1015\n",
            "Epoch 5/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9809 - val_loss: 0.0892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6b770029e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgjHHzenqgZb",
        "outputId": "4ad6e26b-f953-4032-b909-41feec4e6e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9879 - loss: 0.0597\n",
            "Test Accuracy: 0.9892376661300659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkndXSKIq4Ju",
        "outputId": "00cc7982-ea01-4f92-ecc0-e259c4144c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0572853609919548\n",
            "Test Accuracy: 0.9892376661300659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPiNUzU7sL0n",
        "outputId": "4efac565-2878-4bb5-ca46-3f875031530e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "dBz-jJm1sLq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am_FOYpLsLkt",
        "outputId": "62ae290d-13b0-4538-f844-6751aee53f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9928057553956835\n",
            "Recall: 0.9261744966442953\n",
            "F1 Score: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for a detailed breakdown\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTyG5PrQsLfI",
        "outputId": "c0575b1f-3003-4713-91f0-3ea7333c40f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.99      1.00      0.99       966\n",
            "        Spam       0.99      0.93      0.96       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.99      0.96      0.98      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and predict user input\n",
        "def predict_email(email_text):\n",
        "    # Tokenize and pad the input email text\n",
        "    email_seq = tokenizer.texts_to_sequences([email_text])\n",
        "    email_padded = pad_sequences(email_seq, maxlen=100)\n",
        "\n",
        "    # Predict using the trained model\n",
        "    prediction = model.predict(email_padded)\n",
        "    return \"Spam\" if prediction > 0.5 else \"Ham\"\n",
        "\n",
        "# Take user input\n",
        "print(\"\\n=== Email Spam Detection ===\")\n",
        "while True:\n",
        "    user_input = input(\"Enter an email to classify (or type 'exit' to quit): \").strip()\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    result = predict_email(user_input)\n",
        "    print(f\"Prediction: {result}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbofVrc_rC5D",
        "outputId": "0ca67b5f-a40a-401a-b683-950e26290984"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Email Spam Detection ===\n",
            "Enter an email to classify (or type 'exit' to quit): Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): Upgrade to our premium plan for exclusive access to premium content and features.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Prediction: Spam\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): You're a winner! Click here to claim your exclusive prize.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Prediction: Spam\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): Thank you for your feedback. We're always striving to improve our services.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): We're sorry for the inconvenience. Our website will be back online shortly.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4vAQV5irZX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}